// Metadata created by nebel


[id="client-serde_{context}"]
=  Validate Kafka messages using schemas and Java client serializers/deserializers 

[role="_abstract"]
Kafka producer applications can use serializers to encode messages that conform to a specific event schema. Kafka consumer applications can then use deserializers to validate that messages have been serialized using the correct schema, based on a specific schema ID. 

.{registry} and Kafka client SerDes architecture
ifdef::apicurio-registry,rh-service-registry[]
image::images/getting-started/registry-serdes-architecture.png[Registry SerDes architecture]
endif::[]
ifdef::rh-openshift-sr[]
image::../_images/introduction/registry-serdes-architecture.png[Registry SerDes architecture]
endif::[]

{registry} provides Kafka client serializers/deserializers (SerDes) to validate the following message types at runtime:

* Apache Avro
* Google protocol buffers
* JSON Schema

ifdef::apicurio-registry,rh-service-registry[]
The {registry} Maven repository and source code distributions include the Kafka SerDes implementations for these message types, which Kafka client application developers can use to integrate with the registry. 
endif::[]
ifdef::rh-openshift-sr[]
The {registry} Maven repository includes the Kafka SerDes implementations for these message types, which Kafka client developers can use to integrate with the registry. 
endif::[]

These implementations include custom Java classes for each supported message type, for example, `io.apicurio.registry.serde.avro`, which client applications can use to pull schemas from the registry at runtime for validation. 

[role="_additional-resources"]
.Additional resources
ifdef::apicurio-registry,rh-service-registry[]
* {kafka-client-serdes}
endif::[]
ifdef::rh-openshift-sr[]
* link:https://access.redhat.com/documentation/en-us/red_hat_integration/2021.q3/html/service_registry_user_guide/using-kafka-client-serdes[Red Hat Integration Service Registry documentation on Kafka client SerDes]
endif::[]
