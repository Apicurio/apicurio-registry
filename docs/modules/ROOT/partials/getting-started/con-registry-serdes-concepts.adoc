// Module included in the following assemblies:
//  assembly-using-kafka-client-serdes

[id='registry-serdes-concepts-serde-{context}']
= Kafka client applications and {registry}
Using {registry} decouples schema management from client application configuration. You can enable an application to use a schema from the registry by specifying its URL in the client code.

For example, you can store the schemas to serialize and deserialize messages in the registry, which are then referenced from the applications that use them to ensure that the messages that they send and receive are compatible with those schemas. Kafka client applications can push or pull their schemas from {registry} at runtime.

Schemas can evolve, so you can define rules in {registry}, for example, to ensure that changes to a schema are valid and do not break previous versions used by applications. {registry} checks for compatibility by comparing a modified schema with previous schema versions.

{registry} provides schema registry support for a number of schema technologies such as:

* Avro
* Protobuf
* JSON Schema

These schema technologies can be used by client applications through Kafka client serializer/deserializer (SerDe) services provided by {registry}.  The maturity and usage of the SerDe classes provided by {registry} may vary. See the type-specific sections below for more details about each.

[discrete]
== Producer schema configuration

A producer client application uses a serializer to put the messages that it sends to a specific broker topic into the correct data format.

To enable a producer to use {registry} for serialization:

* xref:registry-serdes-register-{context}[Define and register your schema with {registry}] (optional)
* xref:registry-serdes-config-producer-{context}[Configure the producer client code]:

** URL of {registry}
** {registry} serializer to use with the messages
** Strategy to map the Kafka message to an artifact ID in {registry}
** Strategy to look up or register the schema used for serialization in {registry}

After registering your schema, when you start Kafka and {registry}, you can access the schema to format messages sent to the Kafka broker topic by the producer.  Alternatively (depending on configuration), the producer can automatically register the schema on first use.

If a schema already exists, you can create a new version using the REST API based on compatibility rules defined in {registry}. Versions are used for compatibility checking as a schema evolves. An artifact ID and schema version represents a unique tuple that identifies a schema.

[discrete]
== Consumer schema configuration
A consumer client application uses a deserializer to get the messages that it consumes from a specific broker topic into the correct data format.

To enable a consumer to use {registry} for deserialization:

* xref:registry-serdes-register-{context}[Define and register your schema with {registry}]
* xref:registry-serdes-config-consumer-{context}[Configure the consumer client code]:
** URL of {registry}
** {registry} deserializer to use with the messages
** Input data stream for deserialization

The schema is then retrieved by the deserializer using a global ID written into the message being consumed.  The schema global ID can be located in the message headers or in the message payload itself, depending on the configuration of the producer application.

When locating the global ID in the message payload, the format of the data begins with a magic byte (as a signal to consumers) followed by the global ID and then the message data as normal.

For example:
[source,shell,subs="+quotes,attributes"]
----
# ...
[MAGIC_BYTE]
[GLOBAL_ID]
[MESSAGE DATA]
----

Now, when you start Kafka and {registry}, you can access the schema to format messages received from the Kafka broker topic.
