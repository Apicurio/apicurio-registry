# =============================================================================
# Apicurio Registry LangChain4j Demo Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Apicurio Registry Connection
# -----------------------------------------------------------------------------
# URL of the Apicurio Registry instance
apicurio.registry.url=http://localhost:8080

# Default group for prompt templates (use "default" if not specified)
apicurio.registry.default-group=default

# Enable prompt template caching (recommended for production)
apicurio.registry.cache-enabled=true

# -----------------------------------------------------------------------------
# LLM Provider: Ollama (Default - Free, Local)
# -----------------------------------------------------------------------------
# Ollama runs locally and is completely free. No API key required.
# Install: brew install ollama && brew services start ollama && ollama pull llama3.2
quarkus.langchain4j.ollama.base-url=http://localhost:11434
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2
quarkus.langchain4j.ollama.chat-model.temperature=0.7
quarkus.langchain4j.ollama.timeout=120s

# -----------------------------------------------------------------------------
# LLM Provider: OpenAI (Alternative - Paid API)
# -----------------------------------------------------------------------------
# To use OpenAI instead of Ollama:
# 1. Replace quarkus-langchain4j-ollama with quarkus-langchain4j-openai in pom.xml
# 2. Uncomment the lines below and comment out the Ollama config above
# 3. Set OPENAI_API_KEY environment variable
#
# quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
# quarkus.langchain4j.openai.chat-model.temperature=0.7

# -----------------------------------------------------------------------------
# Application Configuration
# -----------------------------------------------------------------------------
# Port 8081 to avoid conflict with Apicurio Registry on 8080
quarkus.http.port=8081

# -----------------------------------------------------------------------------
# Easy RAG Configuration (Document Ingestion for Support Chat)
# -----------------------------------------------------------------------------
# Path to documentation files for RAG ingestion (relative to project root or absolute)
quarkus.langchain4j.easy-rag.path=src/main/resources/docs

# Segment size for document chunking (in characters)
quarkus.langchain4j.easy-rag.max-segment-size=500

# Overlap between segments to maintain context
quarkus.langchain4j.easy-rag.max-overlap-size=100

# Number of relevant documents to retrieve for each query
quarkus.langchain4j.easy-rag.max-results=5

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
quarkus.log.category."io.apicurio".level=DEBUG
quarkus.log.category."dev.langchain4j".level=DEBUG
